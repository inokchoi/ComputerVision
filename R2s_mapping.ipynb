{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.R2s_mapping(full_version).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inokchoi/ComputerVision/blob/main/R2s_mapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j1oJ61DXwOT"
      },
      "source": [
        "# TASK 2. R2* Mapping (Multi-Layer Perceptron)\n",
        "\n",
        "### **We are going to train the MLP to estimate the R2* of each voxel using MRI data. The overall procedure is following:**\n",
        "\n",
        "> **1. Data preparation**  \n",
        "**2. define the network architecture**  \n",
        "**3. train the network**  \n",
        "**4. test the trianed network**  \n",
        "\n",
        "\n",
        "![ ](https://blogfiles.pstatic.net/MjAxOTA5MTBfMTUw/MDAxNTY4MTAzNDExNjEx.1mLJ0eR2qgTUql3Rg8eZ52urXAvz1z5aaK39xmp3JEUg.ccAfmkXluOlasS80oOtOsxEN-ZTqyf5mjsVLGUM_R7Ig.PNG.susie1513/process.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI_A2MQx7Get"
      },
      "source": [
        "# import libraries\n",
        "# don't forget to do drive mount for data loading\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import io\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmu5ssrLYHos"
      },
      "source": [
        "# 1. Data Preparation \n",
        "\n",
        "### First, we have to load the MRI simulation data. Since collecting wide range of in vivo signals is difficult, we use simulation data for training. For simulation data, mono-exponential decay is used with following ranges of input variables : A ∈ [0.8,0.81,...,1.5] ,  T2 * ∈ [10,11,...299,300,310,...,1500] ms.\n",
        "\n",
        "\n",
        "![ ](https://postfiles.pstatic.net/MjAxOTA5MTBfMjgx/MDAxNTY4MTAzMTA3MDQy.qeHFDVnYxIaGpHot_2aMCeDK5NhnzB7vyyrhwBBROZ0g.uVvsJRE-M1Jj4ivhIxZCU3aph0tm4kVNQacevDnL1wwg.PNG.susie1513/monodecay.png?type=w580\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq6JMG0U7I9z",
        "outputId": "7d725436-79fd-4379-d27c-320392f42ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "f = h5py.File('/content/drive/My Drive/Colab Notebooks/TASK2.Data/train_R2s.h5', 'r')\n",
        "\n",
        "X_train = f['X_train']\n",
        "X_train = np.float32(X_train)\n",
        "X_train = torch.from_numpy(X_train)\n",
        "\n",
        "Y_train = f['Y_train']\n",
        "Y_train = np.float32(Y_train)\n",
        "Y_train = torch.from_numpy(Y_train)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([244620, 11])\n",
            "torch.Size([244620, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v5E7F-xi5-f"
      },
      "source": [
        "# 2. Define the network architecture \n",
        "\n",
        "### Now we will define our own network architecture. The network takes a 11 echo MRI signals, and yields R2* value of each voxel. We used mean-squared-error which is commonly adopted in regression problems.\n",
        "\n",
        "\n",
        "![ ](https://postfiles.pstatic.net/MjAxOTA5MTFfMjY2/MDAxNTY4MTk4MTMwMjkx.G7TvEFeAXjt6Wmd6mcAgrRxQOsuC6XV7CCyfZmi9LHgg.IEoWPd7JFZMrips8uNxdwbSiK1v364n96szYfOmmqMwg.PNG.susie1513/networks.png?type=w580\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvjsCbIxsiUK",
        "outputId": "1a11d41f-144b-4097-d605-6d5653580818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aqbYtKS8PxF",
        "outputId": "aba0287c-c90b-4dd7-bf8a-f426d062fb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "class R2s_model(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(R2s_model, self).__init__()       \n",
        "        self.fc1 = nn.Linear(11, 300)\n",
        "        self.fc2 = nn.Linear(300, 300)\n",
        "        self.fc3 = nn.Linear(300, 1)  \n",
        "        \n",
        "        # gpu setting\n",
        "        if use_cuda:\n",
        "            self.fc1 = self.fc1.cuda()\n",
        "            self.fc2 = self.fc2.cuda()\n",
        "            self.fc3 = self.fc3.cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))       \n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = nn.Sigmoid()(self.fc3(x))\n",
        "        return x\n",
        "    \n",
        "model = R2s_model()\n",
        "print(model)\n",
        "\n",
        "# loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2s_model(\n",
            "  (fc1): Linear(in_features=11, out_features=300, bias=True)\n",
            "  (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (fc3): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uloM1yDwQ0sd"
      },
      "source": [
        "# 3. Train the network\n",
        "\n",
        "### The steps for training are \n",
        "\n",
        "\n",
        "\n",
        "> **1. Clear the gradients of all variables**  \n",
        "**2. Compute the predicted outputs by passing foward inputs to the model (forward pass)**  \n",
        "**3. Calcuate the loss using the loss function that we defined**  \n",
        "**4. Compute the gradient of the loss**  \n",
        "**5. Perform a single optimization step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFwpmZ_D9ag9",
        "outputId": "9627a963-9644-43ad-d1c4-74f5b9eb5195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "batch_size = 5000\n",
        "n_batches = X_train.shape[0]//batch_size\n",
        "n_epoch = 200\n",
        "\n",
        "plot_loss = []\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    \n",
        "    train_loss = 0.0  \n",
        "    iteration = 0\n",
        "        \n",
        "    for ii in range(n_batches):\n",
        "\n",
        "        x_train = Variable(X_train[ii*batch_size:(ii+1)*batch_size,:], requires_grad = True)\n",
        "        y_train = Variable(Y_train[ii*batch_size:(ii+1)*batch_size,:], requires_grad = True)\n",
        "      \n",
        "        if use_cuda:\n",
        "            x_train = x_train.cuda()\n",
        "            y_train = y_train.cuda()\n",
        "        \n",
        "        # 1. clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # 2. forward pass\n",
        "        res_x = model(x_train)\n",
        "        \n",
        "        # 3. calculate the loss\n",
        "        loss = criterion(res_x, y_train)\n",
        "        \n",
        "        # 4. backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # 5. parameter update\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update training loss\n",
        "        train_loss += loss.item()\n",
        "        iteration += 1\n",
        "        \n",
        "    # calculate average loss over one epoch    \n",
        "    train_loss = train_loss/iteration\n",
        "    \n",
        "    if (epoch+1)%5 == 0 :\n",
        "      print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5 \tTraining Loss: 0.004654\n",
            "Epoch: 10 \tTraining Loss: 0.000988\n",
            "Epoch: 15 \tTraining Loss: 0.000695\n",
            "Epoch: 20 \tTraining Loss: 0.000524\n",
            "Epoch: 25 \tTraining Loss: 0.000416\n",
            "Epoch: 30 \tTraining Loss: 0.000344\n",
            "Epoch: 35 \tTraining Loss: 0.000294\n",
            "Epoch: 40 \tTraining Loss: 0.000257\n",
            "Epoch: 45 \tTraining Loss: 0.000228\n",
            "Epoch: 50 \tTraining Loss: 0.000205\n",
            "Epoch: 55 \tTraining Loss: 0.000183\n",
            "Epoch: 60 \tTraining Loss: 0.000165\n",
            "Epoch: 65 \tTraining Loss: 0.000151\n",
            "Epoch: 70 \tTraining Loss: 0.000139\n",
            "Epoch: 75 \tTraining Loss: 0.000129\n",
            "Epoch: 80 \tTraining Loss: 0.000121\n",
            "Epoch: 85 \tTraining Loss: 0.000114\n",
            "Epoch: 90 \tTraining Loss: 0.000108\n",
            "Epoch: 95 \tTraining Loss: 0.000102\n",
            "Epoch: 100 \tTraining Loss: 0.000097\n",
            "Epoch: 105 \tTraining Loss: 0.000092\n",
            "Epoch: 110 \tTraining Loss: 0.000088\n",
            "Epoch: 115 \tTraining Loss: 0.000084\n",
            "Epoch: 120 \tTraining Loss: 0.000081\n",
            "Epoch: 125 \tTraining Loss: 0.000078\n",
            "Epoch: 130 \tTraining Loss: 0.000075\n",
            "Epoch: 135 \tTraining Loss: 0.000073\n",
            "Epoch: 140 \tTraining Loss: 0.000071\n",
            "Epoch: 145 \tTraining Loss: 0.000069\n",
            "Epoch: 150 \tTraining Loss: 0.000067\n",
            "Epoch: 155 \tTraining Loss: 0.000066\n",
            "Epoch: 160 \tTraining Loss: 0.000064\n",
            "Epoch: 165 \tTraining Loss: 0.000063\n",
            "Epoch: 170 \tTraining Loss: 0.000062\n",
            "Epoch: 175 \tTraining Loss: 0.000061\n",
            "Epoch: 180 \tTraining Loss: 0.000061\n",
            "Epoch: 185 \tTraining Loss: 0.000060\n",
            "Epoch: 190 \tTraining Loss: 0.000059\n",
            "Epoch: 195 \tTraining Loss: 0.000059\n",
            "Epoch: 200 \tTraining Loss: 0.000058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AynF5VZlQ4Vl"
      },
      "source": [
        "# 4. Test the trained network\n",
        "\n",
        "### We test our model on unseen In vivo data and compared with conventional method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skXdfLaO-mb8",
        "outputId": "f0baae8a-d1a5-48a1-ec2b-4f17f4f61872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load test in vivo dataset\n",
        "meas = io.loadmat('/content/drive/My Drive/Colab Notebooks/exercise_ANN/test_data_mgre.mat')\n",
        "meas = meas['meas']\n",
        "yy,xx,zz,ee = meas.shape\n",
        "\n",
        "# Input normalization\n",
        "meas2 = np.zeros([yy,xx,zz,ee])\n",
        "for i in range(yy):\n",
        "    for j in range(xx):\n",
        "        for k in range(zz):\n",
        "            meas2[i,j,k,:] = meas[i,j,k,:]/meas[i,j,k,0]   \n",
        "            \n",
        "print(meas2.shape)\n",
        "\n",
        "# make the in vivo image to 2D torch array for network input\n",
        "meas3 = np.reshape(meas2,[yy*xx*zz,ee])\n",
        "meas3 = np.float32(meas3)\n",
        "meas4 = torch.from_numpy(meas3)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if use_cuda:\n",
        "    meas4 = meas4.cuda()\n",
        "    \n",
        "# get outputs\n",
        "res_temp = model(meas4)\n",
        "\n",
        "# perpare images for display\n",
        "res_temp = res_temp.data.cpu().numpy()\n",
        "\n",
        "# reshape the result to 3D image \n",
        "R2 = np.reshape(res_temp,[yy,xx,zz])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(192, 192, 32, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVnecOqkUYE7",
        "outputId": "f38c56d5-bdc5-4612-daae-1ccf24fa0dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# load conventional fitting result to compare\n",
        "label = io.loadmat('/content/drive/My Drive/Colab Notebooks/exercise_ANN/test_label_r2s.mat')\n",
        "R2_true = label['R2']\n",
        "\n",
        "# plot the images with conventional method and the differences of two images\n",
        "fig = plt.figure(figsize=(20, 7))\n",
        "\n",
        "nslice = 10\n",
        "R2_pred_show = np.squeeze(R2[:,:,nslice-1:nslice])*100\n",
        "R2_label_show = np.squeeze(R2_true[:,:,nslice-1:nslice])\n",
        "\n",
        "ax = fig.add_subplot(1, 3, 1, xticks=[], yticks=[])\n",
        "ax.imshow(np.squeeze(R2_pred_show), cmap='gray',vmin=0,vmax=100)\n",
        "ax.set_title(\"DL R2\")\n",
        "\n",
        "ax = fig.add_subplot(1, 3, 2, xticks=[], yticks=[])\n",
        "ax.imshow(np.squeeze(R2_label_show), cmap='gray',vmin=0,vmax=100)\n",
        "ax.set_title(\"Fitting R2\")\n",
        "\n",
        "ax = fig.add_subplot(1, 3, 3, xticks=[], yticks=[])\n",
        "ax.imshow(np.squeeze(np.abs(R2_pred_show-R2_label_show))*10, cmap='gray',vmin=0,vmax=100)\n",
        "ax.set_title(\"|DL - Fitting|*10\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-263a22e629b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/19-2 medical image/R2sData/test_label_r2s.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mR2_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot the images with conventional method and the differences of two images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'io' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M2I2A_bUKuK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}