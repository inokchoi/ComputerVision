{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_99.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inokchoi/ComputerVision/blob/main/CNN_99.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orsbJnMcQr-7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUapi9mtQiMW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz1RzmwIQqV0"
      },
      "source": [
        "tf.set_random_seed(777)\n",
        " \n",
        "mnist = input_data.read_data_sets(\"MINST_data/\",one_hot=True)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "#모델 저장 경로\n",
        "save_file = './model'\n",
        "#TensorBoard log 저장 경로\n",
        "logs_path = './logs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNC1XfT4ymLq"
      },
      "source": [
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "#28*28이미지 -> X를 784(28*28)\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "#이미지를 받아올 X_img\n",
        "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
        "#Label을 받아올 Y\n",
        "Y = tf.placeholder(tf.float32, [None,10])\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
        "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1],padding='SAME')\n",
        "L1 = tf.nn.relu(L1)\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
        " \n",
        "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1],padding='SAME')\n",
        "L2 = tf.nn.relu(L2)\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
        " \n",
        "W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
        "L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1],padding='SAME')\n",
        "L3 = tf.nn.relu(L3)\n",
        "L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
        "L3_flat = tf.reshape(L3, [-1, 128*4*4])\n",
        " \n",
        "W4 = tf.get_variable(\"W4\", shape=[128*4*4, 625], initializer = tf.contrib.layers.xavier_initializer())\n",
        "b4 = tf.Variable(tf.random_normal([625]))\n",
        "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
        "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
        " \n",
        "W5 = tf.get_variable(\"W5\", shape = [625,10], initializer = tf.contrib.layers.xavier_initializer())\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "logits = tf.matmul(L4,W5) + b5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8uDgCNrQ6jA",
        "outputId": "e7394308-040c-4284-e4c0-7bff781ef54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(Y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-68e277ef871a>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqS1XUWKgAGO"
      },
      "source": [
        "# Create a summary to monitor cost tensor\n",
        "tf.summary.scalar(\"loss\", cost)\n",
        "# Create a summary to monitor accuracy tensor\n",
        "tf.summary.scalar(\"accuracy\", accuracy)\n",
        "# Merge all summaries into a single op\n",
        "merged_summary_op = tf.summary.merge_all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezyIwAoSQ8fP",
        "outputId": "c70a9d44-50e8-410b-e0ef-6ed59ad00cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0\n",
        "        total_batch = int(mnist.train.num_examples / batch_size)\n",
        "    \n",
        "        for i in range(total_batch):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
        "            c, _, summary = sess.run([cost, optimizer, merged_summary_op], feed_dict=feed_dict)\n",
        "            summary_writer.add_summary(summary, epoch * total_batch + i)\n",
        "            avg_cost += c/total_batch\n",
        " \n",
        "        print('Epoch;', '%04d' % (epoch +1), 'cost =', '{:.9f}'.format(avg_cost)) \n",
        "    print('Learning Finished')\n",
        "    print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
        "    \n",
        "    # Save the model\n",
        "    saver.save(sess, save_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch; 0001 cost = 0.365652760\n",
            "Epoch; 0002 cost = 0.102024115\n",
            "Epoch; 0003 cost = 0.073605365\n",
            "Epoch; 0004 cost = 0.060561172\n",
            "Epoch; 0005 cost = 0.050102010\n",
            "Epoch; 0006 cost = 0.045606690\n",
            "Epoch; 0007 cost = 0.043939578\n",
            "Epoch; 0008 cost = 0.038386950\n",
            "Epoch; 0009 cost = 0.035203932\n",
            "Epoch; 0010 cost = 0.035286386\n",
            "Epoch; 0011 cost = 0.029418148\n",
            "Epoch; 0012 cost = 0.030336113\n",
            "Epoch; 0013 cost = 0.028220017\n",
            "Epoch; 0014 cost = 0.025865923\n",
            "Epoch; 0015 cost = 0.025325084\n",
            "Learning Finished\n",
            "Accuracy: 0.9938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OITZTWAzAb3"
      },
      "source": [
        "TensorBoard 실행을 위한 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT_mh3JWjK-p",
        "outputId": "7c454a3e-7a93-4dbc-b95e-9db974780ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "if not os.path.exists(logs_path):\n",
        "  os.makedirs(logs_path)\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(logs_path))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-07 15:07:05--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.214.169.236, 52.54.237.49, 3.219.201.17, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.214.169.236|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13607069 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  55%[==========>         ]   7.21M  35.9MB/s               \rngrok-stable-linux- 100%[===================>]  12.98M  46.7MB/s    in 0.3s    \n",
            "\n",
            "2019-10-07 15:07:05 (46.7 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13607069/13607069]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "https://471fc14d.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}